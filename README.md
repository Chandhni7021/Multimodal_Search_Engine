ğŸ” Multimodal Search Engine (Text + Images) using CLIP

Semantic search inside PDFs â€” across both text and images â€” using OpenAIâ€™s CLIP model.

A real AI-powered search engine for any document.
Built as part of my #365DaysOfAI challenge â€” Day 16.

âœ¨ What It Does

Upload any PDF â†’ search with a natural query â†’ get semantically matched results from:

  ğŸ“„ Text chunks

  ğŸ–¼ Images extracted from the PDF

No keyword matching. No manual tagging.
Just meaning-powered retrieval using OpenAIâ€™s CLIP embeddings and cosine similarity.
ğŸ’¡ Example Queries

  â€œscanning garmentsâ€

  â€œrobot sewing fabricâ€

  â€œprivacy concerns in AIâ€

  â€œchart about revenueâ€

  â€œdiagram of neural networkâ€

ğŸ“¦ Features

âœ… Extract text chunks from any PDF
âœ… Extract all images with page metadata
âœ… Generate CLIP embeddings for both text & images
âœ… Cosine similarity search with your query
âœ… Clean Streamlit UI to view & filter results
ğŸ“ Folder Structure

multimodal_search/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ source.pdf â† your input PDF
â”‚ â””â”€â”€ images/ â† extracted images
â”œâ”€â”€ embeddings/ â† stores .pkl embeddings
â”‚ â”œâ”€â”€ text.pkl
â”‚ â””â”€â”€ images.pkl
â”œâ”€â”€ search.py â† runs preprocessing
â”œâ”€â”€ streamlit_app.py â† Streamlit UI
â””â”€â”€ utils.py â† core logic (CLIP, extraction, search)
ğŸš€ Quick Start

  Clone this repo:

git clone https://github.com/yourusername/multimodal-search-ai.git
cd multimodal-search-ai

  Create a virtual environment (optional but recommended):

python -m venv .venv
.venv\Scripts\activate  # Windows

  Install dependencies:

pip install -r requirements.txt

  Place your PDF at:

ğŸ“„ data/source.pdf

  Run preprocessing:

python search.py

  Launch the Streamlit UI:

streamlit run streamlit_app.py

![Screenshot 2025-06-25 123837](https://github.com/user-attachments/assets/7e3909ab-35e9-41a7-b2ed-eff29e2efbac)
![Screenshot 2025-06-25 123849](https://github.com/user-attachments/assets/7b612a59-c760-41d2-8285-eca0d844addf)
![Screenshot 2025-06-25 123901](https://github.com/user-attachments/assets/2aba7fcc-7453-46e1-9307-14353aeb0433)


(You can replace these placeholder images with your own screenshots)
ğŸ§  Built With

  OpenAI CLIP

  PyMuPDF (fitz) for PDF parsing

  Streamlit for UI

  sklearn + torch for embeddings and similarity

ğŸ§µ TailorAI Demo

I tested this project on a tailoring tech PDF (TailorAI) to simulate real-world fashion search use cases.

Examples:

  "Scan garments" â†’ returned body scanning text

  "Fabric cutting robot" â†’ returned diagrams + automation logic

  "Data privacy" â†’ matched security policy lines

This could be a game-changer for fashion tech, education, or legal documents!
ğŸŒ Use Cases

   ğŸ“š Semantic search in academic papers

   ğŸ› Legal & policy docs

  ğŸ§µ Fashion design or AI tailoring

    ğŸ§  E-learning & training materials

    ğŸ“¸ Design/image-based reports

ğŸ“„ License

MIT License
